@article{Rushworth2008,
abstract = {Reinforcement learning models that focus on the striatum and dopamine can predict the choices of animals and people. Representations of reward expectation and of reward prediction errors that are pertinent to decision making, however, are not confined to these regions but are also found in prefrontal and cingulate cortex. Moreover, decisions are not guided solely by the magnitude of the reward that is expected. Uncertainty in the estimate of the reward expectation, the value of information that might be gained by taking a course of action and the cost of an action all influence the manner in which decisions are made through prefrontal and cingulate cortex.},
author = {Rushworth, Matthew F.S. and Behrens, Timothy E J},
doi = {10.1038/nn2066},
file = {:Users/rasmus/Library/Application Support/Mendeley Desktop/Downloaded/Rushworth, Behrens - 2008 - Choice, uncertainty and value in prefrontal and cingulate cortex(2).pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Animals,Choice Behavior,Decision Making,Gyrus Cinguli,Gyrus Cinguli: physiology,Humans,Prefrontal Cortex,Prefrontal Cortex: physiology,Probability Learning,Psychological Theory,Reinforcement (Psychology),Risk Assessment,Uncertainty},
month = {apr},
number = {4},
pages = {389--97},
pmid = {18368045},
title = {{Choice, uncertainty and value in prefrontal and cingulate cortex}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18368045},
volume = {11},
year = {2008}
}
@article{Rangel2008a,
abstract = {Neuroeconomics is the study of the neurobiological and computational basis of value-based decision making. Its goal is to provide a biologically based account of human behaviour that can be applied in both the natural and the social sciences. This Review proposes a framework to investigate different aspects of the neurobiology of decision making. The framework allows us to bring together recent findings in the field, highlight some of the most important outstanding problems, define a common lexicon that bridges the different disciplines that inform neuroeconomics, and point the way to future applications.},
author = {Rangel, Antonio and Camerer, Colin and Montague, P Read},
doi = {10.1038/nrn2357},
file = {:Users/rasmus/Library/Application Support/Mendeley Desktop/Downloaded/Rangel, Camerer, Montague - 2008 - A framework for studying the neurobiology of value-based decision making(4).pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$n1471-003X (Linking)},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
pages = {545--556},
pmid = {18545266},
title = {{A framework for studying the neurobiology of value-based decision making.}},
volume = {9},
year = {2008}
}
@article{Niv2008,
abstract = {The recognition that computational ideas from reinforcement learning are relevant to the study of neural circuits has taken the cognitive neuroscience community by storm. A central tenet of these models is that discrepancies between actual and expected outcomes can be used for learning. Neural correlates of such prediction-error signals have been observed now in midbrain dopaminergic neurons, striatum, amygdala and even prefrontal cortex, and models incorporating prediction errors have been invoked to explain complex phenomena such as the transition from goal-directed to habitual behavior. Yet, like any revolution, the fast-paced progress has left an uneven understanding in its wake. Here, we provide answers to ten simple questions about prediction errors, with the aim of exposing both the strengths and the limitations of this active area of neuroscience research.},
author = {Niv, Yael and Schoenbaum, Geoffrey},
doi = {10.1016/j.tics.2008.03.006},
file = {:Users/rasmus/Library/Application Support/Mendeley Desktop/Downloaded/Niv, Schoenbaum - 2008 - Dialogues on prediction errors(2).pdf:pdf},
issn = {1364-6613},
journal = {Trends in Cognitive Sciences},
keywords = {Artificial Intelligence,Association Learning,Brain,Brain: physiology,Discrimination Learning,Dopamine,Dopamine: physiology,Humans,Models,Neurological,Probability Learning,Psychological,Psychological Theory,Reinforcement (Psychology)},
month = {jul},
number = {7},
pages = {265--72},
pmid = {18567531},
title = {{Dialogues on prediction errors}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18567531},
volume = {12},
year = {2008}
}
@incollection{Daw2013,
author = {Daw, Nathaniel D and Tobler, Philippe N},
booktitle = {Neuroeconomics},
file = {:Users/rasmus/Library/Application Support/Mendeley Desktop/Downloaded/Daw, Tobler - 2014 - Value learning through reinforcement The basics of dopamine and reinforcement learning.pdf:pdf},
isbn = {9780124160088},
pages = {283--298},
title = {{Value learning through reinforcement: The basics of dopamine and reinforcement learning}},
year = {2014}
}
@article{Lisman2005,
author = {Lisman, John E and Grace, Anthony A},
doi = {10.1016/j.neuron.2005.05.002},
journal = {Neuron},
number = {5},
pages = {703--713},
title = {{The hippocampal-VTA loop: Controlling the entry of information into long-term memory}},
volume = {46},
year = {2005}
}
@article{Wimmer2014,
abstract = {Learning is essential for adaptive decision making. The striatum and its dopaminergic inputs are known to support incremental reward-based learning, while the hippocampus is known to support encoding of single events (episodic memory). Although traditionally studied separately, in even simple experiences, these two types of learning are likely to co-occur and may interact. Here we sought to understand the nature of this interaction by examining how incremental reward learning is related to concurrent episodic memory encoding. During the experiment, human participants made choices between two options (colored squares), each associated with a drifting probability of reward, with the goal of earning as much money as possible. Incidental, trial-unique object pictures, unrelated to the choice, were overlaid on each option. The next day, participants were given a surprise memory test for these pictures. We found that better episodic memory was related to a decreased influence of recent reward experience on choice, both within and across participants. fMRI analyses further revealed that during learning the canonical striatal reward prediction error signal was significantly weaker when episodic memory was stronger. This decrease in reward prediction error signals in the striatum was associated with enhanced functional connectivity between the hippocampus and striatum at the time of choice. Our results suggest a mechanism by which memory encoding may compete for striatal processing and provide insight into how interactions between different forms of learning guide reward-based decision making.},
author = {Wimmer, G. E. and Braun, E. K. and Daw, N. D. and Shohamy, D.},
doi = {10.1523/JNEUROSCI.0204-14.2014},
file = {:Users/rasmus/Dropbox/Paper/Pivotal/Wimmer2014.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {decision making,hippocampus,learning,memory,reward,striatum},
number = {45},
pages = {14901--14912},
pmid = {25378157},
title = {{Episodic Memory Encoding Interferes with Reward Learning and Decreases Striatal Prediction Errors}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0204-14.2014},
volume = {34},
year = {2014}
}
@article{Henson2010,
abstract = {Most lesion studies in animals, and neuropsychological and functional neuroimaging studies in humans, have focused on finding dissociations between the functions of different brain regions, for exam-ple in relation to different types of memory. While some of these disso-ciations can be questioned, particularly in the case of neuroimaging data, we start by assuming a ''modal model'' in which at least three dif-ferent memory systems are distinguished: an episodic system (which stores associations between items and spatial/temporal contexts, and which is supported primarily by the hippocampus); a semantic system (which extracts combinations of perceptual features that define items, and which is supported primarily by anterior temporal cortex); and modality-specific perceptual systems (which represent the sensory features extracted from a stimulus, and which are supported by higher sensory cortices). In most situations however, behavior is determined by interactions between these systems. These interactions reflect the flow of information in both ''forward'' and ''backward'' directions between memory systems, where backward connections transmit predictions about the current item/features based on the current context/item. Importantly, it is the resulting ''prediction error''—the difference between these predictions and the forward transmission of sensory evidence—that drives memory encoding and retrieval. We describe how this ''predictive inter-active multiple memory systems'' (PIMMS) framework can be applied to human neuroimaging data acquired during encoding or retrieval phases of the recognition memory paradigm. Our novel emphasis is thus on associa-tions rather than dissociations between activity measured in key brain regions; in particular, we propose that measuring the functional coupling between brain regions will help understand how these memory systems interact to guide behavior.},
author = {Henson, Richard N. and Gagnepain, Pierre},
doi = {10.1002/hipo.20857},
file = {:Users/rasmus/Dropbox/Paper/Pivotal/Henson2010.pdf:pdf},
isbn = {1098-1063},
issn = {10509631},
journal = {Hippocampus},
keywords = {Familiarity,Memory systems,Priming,Recollection},
number = {11},
pages = {1315--1326},
pmid = {20928831},
title = {{Predictive, interactive multiple memory systems}},
volume = {20},
year = {2010}
}
@article{Greve2017,
abstract = {The role of prediction error (PE) in driving learning is well-established in fields such as classical and instrumental conditioning, reward learning and procedural memory; however, its role in human one-shot declarative encoding is less clear. According to one recent hypothesis, PE reflects the divergence between two probability distributions: one reflecting the prior probability (from previous experiences) and the other reflecting the sensory evidence (from the current experience). Assuming unimodal probability distributions, PE can be manipulated in three ways: (1) the distance between the mode of the prior and evidence, (2) the precision of the prior, and (3) the precision of the evidence. We tested these three manipulations across five experiments, in terms of peoples' ability to encode a single presentation of a scene-item pairing as a function of previous exposures to that scene and/or item. Memory was probed by presenting the scene together with three choices for the previously paired item, in which the two foil items were from other pairings within the same condition as the target item. In Experiment 1, we manipulated the evidence to be either consistent or inconsistent with prior expectations, predicting PE to be larger, and hence memory better, when the new pairing was inconsistent. In Experiments 2a–c, we manipulated the precision of the priors, predicting better memory for a new pairing when the (inconsistent) priors were more precise. In Experiment 3, we manipulated both visual noise and prior exposure for unfamiliar faces, before pairing them with scenes, predicting better memory when the sensory evidence was more precise. In all experiments, the PE hypotheses were supported. We discuss alternative explanations of individual experiments, and conclude the Predictive Interactive Multiple Memory Signals (PIMMS) framework provides the most parsimonious account of the full pattern of results.},
author = {Greve, Andrea and Cooper, Elisa and Kaula, Alexander and Anderson, Michael C. and Henson, Richard},
doi = {10.1016/j.jml.2016.11.001},
file = {:Users/rasmus/Dropbox/Paper/Pivotal/Greve2017.pdf:pdf},
isbn = {0749-596X},
issn = {0749596X},
journal = {Journal of Memory and Language},
keywords = {Associative memory,Encoding,One-shot learning,Prediction error},
pages = {149--165},
pmid = {28579691},
publisher = {The Authors},
title = {{Does prediction error drive one-shot declarative learning?}},
url = {http://dx.doi.org/10.1016/j.jml.2016.11.001},
volume = {94},
year = {2017}
}
@article{Bahar2011a,
abstract = {Memory influences learning, but how neural signals support such transfer are unknown. To investigate these mechanisms, we trained rats to perform a standard spatial memory task in a plus maze and tested how training affected learning and neural coding in two new task variants. A switch task exchanged the start and goal locations in the same environment, whereas, an altered environment task contained unfamiliar local and distal cues. Learning was facilitated in both variants compared with the acquisition of the standard task. In the switch task, performance was largely maintained, and was accompanied by immediate and stable place-field remapping. Place-field maps in CA1 were anticorrelated in the standard and switch sessions, and the anticorrelation covaried with switch performance. Simultaneously, CA3 maps were uncorrelated overall in the standard and switch, though many CA3 cells had fields in shifted locations in the same maze arms. In the altered environment, performance was initially impaired, and place fields changed dynamically. CA1 fields were initially unstable, and their stabilization correlated with improving performance. Most CA3 cells, however, stopped firing on the maze in the altered environment, even as the same cells maintained prominent fields in standard sessions recorded before and after. CA1 and CA3 place fields thus revealed different coding dynamics that correlated with both learning and memory performance. Together, CA1 and CA3 ensembles represented the similarities and differences between new and familiar situations through concurrent rate and place remapping.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Bahar, A. S. and Shirvalkar, P. R. and Shapiro, M. L.},
doi = {10.1523/JNEUROSCI.1671-11.2011},
eprint = {NIHMS150003},
file = {:Users/rasmus/Dropbox/Paper/Pivotal/Bahar2011.full.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {34},
pages = {12270--12281},
pmid = {21865470},
title = {{Memory-Guided Learning: CA1 and CA3 Neuronal Ensembles Differentially Encode the Commonalities and Differences between Situations}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1671-11.2011},
volume = {31},
year = {2011}
}
@article{Finch2009a,
abstract = {In these notes I explain how to derive formulae for numerically stable calculation of the mean and standard deviation, which are also suitable for incremental on-line calculation. I then generalize these formulae to weighted means and standard deviations. I unpick the diﬃculties that arise when generalizing further to normalized weights. Finally I show that the exponentially weighted moving average is a special case of the incremental normalized weighted mean formula, and derive a formula for the exponentially weighted moving standard deviation.},
archivePrefix = {arXiv},
arxivId = {1111.0092},
author = {Finch, Tony},
doi = {10.1143/PTP.126.993},
eprint = {1111.0092},
file = {:Users/rasmus/Dropbox/Paper/Pivotal/Finch2009.pdf:pdf},
isbn = {0184-7783},
issn = {0033-068X},
journal = {General Relativity and Gravitation},
keywords = {ADP,weighted sample variance},
number = {4},
pages = {511--520},
title = {{Incremental calculation of weighted mean and variance}},
url = {http://ptp.oxfordjournals.org/content/126/6/993.abstract},
volume = {39},
year = {2009}
}
@article{Gershman2014a,
abstract = {Psychophysical and neurophysiological studies have suggested that memory is not simply a carbon copy of our experience: Memories are modified or new memories are formed depending on the dynamic structure of our experience, and specifically, on how gradually or abruptly the world changes. We present a statistical theory of memory formation in a dynamic environment, based on a nonparametric generalization of the switching Kalman filter. We show that this theory can qualitatively account for several psychophysical and neural phenomena, and present results of a new visual memory experiment aimed at testing the theory directly. Our experimental findings suggest that humans can use temporal discontinuities in the structure of the environment to determine when to form new memory traces. The statistical perspective we offer provides a coherent account of the conditions under which new experience is integrated into an old memory versus forming a new memory, and shows that memory formation depends on inferences about the underlying structure of our experience.},
author = {Gershman, Samuel J. and Radulescu, Angela and Norman, Kenneth A. and Niv, Yael},
doi = {10.1371/journal.pcbi.1003939},
file = {:Users/rasmus/Dropbox/Paper/Pivotal/Gershman2016.pdf:pdf},
isbn = {1553-7358 (Electronic)$\backslash$r1553-734X (Linking)},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {11},
pmid = {25375816},
title = {{Statistical Computations Underlying the Dynamics of Memory Updating}},
volume = {10},
year = {2014}
}
@article{Gershman2017b,
abstract = {{\textless}p{\textgreater}Retrieving a memory can modify its influence on subsequent behavior. We develop a computational theory of memory modification, according to which modification of a memory trace occurs through classical associative learning, but which memory trace is eligible for modification depends on a structure learning mechanism that discovers the units of association by segmenting the stream of experience into statistically distinct clusters (latent causes). New memories are formed when the structure learning mechanism infers that a new latent cause underlies current sensory observations. By the same token, old memories are modified when old and new sensory observations are inferred to have been generated by the same latent cause. We derive this framework from probabilistic principles, and present a computational implementation. Simulations demonstrate that our model can reproduce the major experimental findings from studies of memory modification in the Pavlovian conditioning literature.{\textless}/p{\textgreater}},
author = {Gershman, Samuel J. and Monfils, Marie H. and Norman, Kenneth A. and Niv, Yael},
doi = {10.7554/eLife.23763},
file = {:Users/rasmus/Dropbox/Paper/Pivotal/Gershman2017.pdf:pdf},
isbn = {2050-084X},
issn = {2050084X},
journal = {eLife},
pages = {1--41},
pmid = {28294944},
title = {{The computational nature of memory modification}},
volume = {6},
year = {2017}
}
@article{Gershman2019,
abstract = {The free energy principle has been proposed as a unifying theory of brain function. It is closely related, and in some cases subsumes, earlier unifying ideas such as Bayesian inference, predictive coding, and active learning. This article clarifies these connections, teasing apart distinctive and shared predictions.},
archivePrefix = {arXiv},
arxivId = {1901.07945},
author = {Gershman, Samuel J.},
eprint = {1901.07945},
file = {:Users/rasmus/Dropbox/Paper/Pivotal/Gershman2019.pdf:pdf},
pages = {1--11},
title = {{What does the free energy principle tell us about the brain?}},
url = {https://arxiv.org/abs/1901.07945{\%}0Ahttp://arxiv.org/abs/1901.07945},
year = {2019}
}
@article{Jang2019,
author = {Jang, Anthony I and Nassar, Matthew R and Dillon, Daniel G and Frank, Michael J},
doi = {10.1038/s41562-019-0597-3.Positive},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jang et al. - 2019 - Positive reward prediction errors during decision making strengthen memory encoding.pdf:pdf},
issn = {2397-3374},
journal = {Nature Human Behaviour},
mendeley-groups = {Lisco/Journal Club},
number = {July},
pages = {719--732},
title = {{Positive reward prediction errors during decision making strengthen memory encoding}},
url = {http://dx.doi.org/10.1038/s41562-019-0597-3},
volume = {3},
year = {2019}
}

@article{VanKesteren2018,
author = {van Kesteren, Marlieke T. R. and Brown, Thackery I. and Wagner, Anthony D.},
doi = {10.3389/fnhum.2018.00486},
file = {:Users/rasmus/Dropbox/Paper/Pivotal/Kesteren2018.pdf:pdf},
issn = {1662-5161},
journal = {Frontiers in Human Neuroscience},
keywords = {frontiers in human neuroscience,frontiersin,hippocampus,medial temporal lobe,memory,memory, schema, prior knowledge, spatial learning,,navigation,org,prior knowledge,prospective planning,schema,spatial learning,www},
number = {December},
pages = {1--16},
title = {{Learned Spatial Schemas and Prospective Hippocampal Activity Support Navigation After One-Shot Learning}},
url = {https://www.frontiersin.org/article/10.3389/fnhum.2018.00486/full},
volume = {12},
year = {2018}
}
@article{Norman2002,
abstract = {The complementary learning systems framework provides a simple set of principles, derived from converging biological, psychological and computational constraints, for understanding the differential contributions of the neocortex and hippocampus to learning and memory. The central principles are that the neocortex has a low learning rate and uses overlapping distributed representations to extract the general statistical structure of the environment, whereas the hippocampus learns rapidly using separated representations to encode the details of specific events while minimizing interference. In recent years, we have instantiated these principles in working computational models, and have used these models to address human and animal learning and memory findings, across a wide range of domains and paradigms. Here, we review a few representative applications of our models, focusing on two domains: recognition memory and animal learning in the fear-conditioning paradigm. In both domains, the models have generated novel predictions that have been tested and confirmed.},
author = {Norman, Kenneth A and O'Reilly, Randall C},
doi = {10.1016/j.acap.2016.05.032},
file = {:Users/rasmus/Dropbox/Paper/Pivotal/Norman2002.pdf:pdf},
issn = {18762859},
journal = {Trends in Cognitive Sciences},
keywords = {animal learning,computational models,hippocampus,memory,neocortex,recognition memory},
number = {12},
pages = {505--510},
title = {{Hippocampal and neocortical contributions to memory: advances in the complementary learning systems framework}},
url = {http://www.sciencedirect.com/science/article/B6VH9-47C8S3T-F/1/0b50ea509799c44aa7dd968493a20767},
volume = {6},
year = {2002}
}
@book{Murphy2012,
address = {Cambridge},
author = {Murphy, Kevin P},
file = {:Users/rasmus/Library/Application Support/Mendeley Desktop/Downloaded/Murphy - 2012 - Machine learning A probabilistic perspective.pdf:pdf},
isbn = {9780262018029},
publisher = {MIT Press},
title = {{Machine learning: A probabilistic perspective}},
year = {2012}
}
@article{Rouhani2018,
author = {Rouhani, Nina and Norman, Kenneth A and Niv, Yael},
file = {:Users/rasmus/Library/Application Support/Mendeley Desktop/Downloaded/Rouhani et al. - 2018 - Dissociable Effects of Surprising Rewards on Learning and Memory.pdf:pdf},
journal = {Journal of Experimental Psychology: Learning Memory, and Cognition},
number = {Advance online publication},
title = {{Dissociable Effects of Surprising Rewards on Learning and Memory}},
year = {2018}
}
@article{Rouhani2021,
abstract = {Memory helps guide behavior, but which experiences from the past are priori-tized? Classic models of learning posit that events associated with unpredictable outcomes as well as, paradoxically, predictable outcomes, deploy more attention and learning for those events. Here, we test reinforcement learning and subsequent memory for those events, and treat signed and unsigned reward prediction errors (RPEs), experienced at the reward-predictive cue or reward outcome, as drivers of these two seemingly contradictory signals. By fitting reinforcement learning models to behavior, we find that both RPEs contribute to learning by modulat-ing a dynamically changing learning rate. We further characterize the effects of these RPE signals on memory, and show that both signed and unsigned RPEs enhance memory, in line with midbrain dopamine and locus-coeruleus modulation of hippocampal plasticity, thereby reconciling separate findings in the literature.},
author = {Rouhani, Nina and Niv, Yael},
doi = {10.7554/eLife.61077},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rouhani, Niv - 2021 - Signed and unsigned reward prediction errors dynamically enhance learning and memory.pdf:pdf},
issn = {2050084X},
journal = {eLife},
mendeley-groups = {Lisco/Journal Club},
number = {Lc},
pages = {1--28},
pmid = {33661094},
title = {{Signed and unsigned reward prediction errors dynamically enhance learning and memory}},
volume = {10},
year = {2021}
}

@book{Sutton1998,
address = {Cambridge},
author = {Sutton, Richard S and Barto, Andrew G.},
file = {:Users/rasmus/Library/Application Support/Mendeley Desktop/Downloaded/Sutton, Barto - 1998 - Reinforcement Learning An Introduction(2).pdf:pdf},
isbn = {0262193981},
publisher = {MIT Press},
title = {{Reinforcement Learning: An Introduction}},
year = {1998}
}
@book{Sutton2018a,
abstract = {Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics. Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including UCB, Expected Sarsa, and Double Learning. Part II extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.},
archivePrefix = {arXiv},
arxivId = {1603.02199},
author = {Sutton, Richard S and Barto, Andrew G},
booktitle = {The Lancet},
doi = {10.1016/S0140-6736(51)92942-X},
eprint = {1603.02199},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutton, Barto - 2018 - Reinforcement Learning An Introduction, Second Edition(2).pdf:pdf},
isbn = {0262193981},
issn = {01406736},
mendeley-groups = {Lisco/computational models},
number = {6685},
pages = {675--676},
pmid = {17044734},
title = {{Reinforcement Learning: An Introduction, Second Edition}},
volume = {258},
year = {2018}
}

@article{Poldrack2001,
author = {Poldrack, Russell A and Clark, J and Par{\'{e}}-Blagoev, E.J. and Shohamy, D. and {Creso Moyano}, J. and Myers, C. and Gluck, M.A},
file = {:Users/rasmus/Dropbox/Paper/Pivotal/Poldrack2001.pdf:pdf},
journal = {Nature},
number = {November},
pages = {546--550},
title = {{Interactive memory systems in the human brain}},
volume = {414},
year = {2001}
}
@article{Friston2009,
abstract = {This paper considers prediction and perceptual categorization as an inference problem that is solved by the brain. We assume that the brain models the world as a hierarchy or cascade of dynamical systems that encode causal structure in the sensorium. Perception is equated with the optimization or inversion of these internal models, to explain sensory data. Given a model of how sensory data are generated, we can invoke a generic approach to model inversion, based on a free energy bound on the model's evidence. The ensuing free-energy formulation furnishes equations that prescribe the process of recognition, i.e. the dynamics of neuronal activity that represent the causes of sensory input. Here, we focus on a very general model, whose hierarchical and dynamical structure enables simulated brains to recognize and predict trajectories or sequences of sensory states. We first review hierarchical dynamical models and their inversion. We then show that the brain has the necessary infrastructure to implement this inversion and illustrate this point using synthetic birds that can recognize and categorize birdsongs.},
author = {Friston, Karl and Kiebel, Stefan},
doi = {10.1098/rstb.2008.0300},
file = {:Users/rasmus/Dropbox/Paper/Pivotal/Friston2009.pdf:pdf},
isbn = {0962-8436},
issn = {14712970},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
keywords = {Birdsong,Generative models,Hierarchical,Predictive coding},
number = {1521},
pages = {1211--1221},
pmid = {19528002},
title = {{Predictive coding under the free-energy principle}},
volume = {364},
year = {2009}
}
@article{Wilson2019a,
abstract = {Computational modeling of behavior has revolutionized psychology and neuroscience. By fitting models to experimental data we can probe the algorithms underlying behavior, find neural correlates of computational variables and better understand the effects of drugs, illness and interventions. But with great power comes great responsibility. Here, we offer ten simple rules to ensure that computational modeling is used with care and yields meaningful insights. In particular, we present a beginner-friendly, pragmatic and details-oriented introduction on how to relate models to data. What, exactly, can a model tell us about the mind? To answer this, we apply our rules to the simplest modeling techniques most accessible to beginning modelers and illustrate them with examples and code available online. However, most rules apply to more advanced techniques. Our hope is that by following our guidelines, researchers will avoid many pitfalls and unleash the power of computational modeling on their own data.},
author = {Wilson, Robert C. and Collins, Anne G.E.},
doi = {10.7554/eLife.49547},
file = {:home/francesco/PowerFolders/Frankfurt{\_}University/Computational{\_}models/Rasmus/Material suggested/elife-49547-v2.pdf:pdf},
issn = {2050084X},
journal = {eLife},
pages = {1--33},
pmid = {31769410},
title = {{Ten simple rules for the computational modeling of behavioral data}},
volume = {8},
year = {2019}
}
@article{Christakou2013a,
abstract = {We examined the maturation of decision-making from early adolescence to mid-adulthood using fMRI of a variant of the Iowa gambling task.Wehavepreviously shown that perfor- mance in this task relies on sensitivity to accumulating negative outcomes in ventromedial PFC and dorsolateral PFC. Here, we further formalize outcome evaluation (as driven by prediction errors [PE], using a reinforcement learning model) and exam- ine its development. Task performance improved significantly during adolescence, stabilizing in adulthood. Performance re- lied on greater impact of negative compared with positive PEs, the relative impact of which matured from adolescence into adulthood. Adolescents also showed increased exploratory behavior, expressed as a propensity to shift responding be- tween options independently of outcome quality, whereas adults showed no systematic shifting patterns. The correlation between PE representation and improved performance strength- ened with age for activation in ventral and dorsal PFC, ventral striatum, and temporal and parietal cortices. There was a medial- lateral distinction in the prefrontal substrates of effective PE utilization between adults and adolescents: Increased utiliza- tion of negative PEs, a hallmark of successful performance in the task, was associated with increased activation in ventro- medial PFC in adults, but decreased activation in ventrolateral PFC and striatum in adolescents. These results suggest that adults and adolescents engage qualitatively distinct neural and psychological processes during decision-making, the develop- ment ofwhich is not exclusively dependent on reward-processing maturation. ■},
author = {Christakou, Anastasia and Gershman, Samuel J. and Niv, Yael and Simmons, Andrew and Brammer, Mick and Rubia, Katya},
doi = {10.1162/jocn},
file = {:home/francesco/Downloads/jocn{\_}a{\_}00447.pdf:pdf},
journal = {Washington, DC: APA, Guideline Development Panel for the Treatment of Posttraumatic Stress Disorder in Adults.},
number = {December},
pages = {139},
title = {{Neural and Psychological Maturation of Decision-making in Adolescence and Young Adulthood}},
url = {https://www.apa.org/ptsd-guideline/ptsd.pdf{\%}0Ahttps://www.apa.org/about/offices/directorates/guidelines/ptsd.pdf},
year = {2013}
}
@article{Ghosh2014,
abstract = {The term "schema" has been used to describe vastly different knowledge structures within the memory neuroscience literature. Ambiguous terminology hinders cross-study comparisons and confounds interpretation of the suggested role of the ventromedial prefrontal cortex (vmPFC) in schema functions. Based on an extensive review of the psychological literature, we propose a framework for distinguishing memory schemas from other knowledge structures. The framework includes a definition of schema as possessing four necessary and sufficient features, and four additional features schemas are sensitive to, which are not required but do play a frequent and central role in schema functions. Necessary schema features are (1) an associative network structure, (2) basis on multiple episodes, (3) lack of unit detail, and (4) adaptability. Features schemas are sensitive to are (5) chronological relationships, (6) hierarchical organization, (7) cross-connectivity, and (8) embedded response options. Additionally, we suggest that vmPFC activity observed in studies of schemas corresponds with participants' coordination of existing schemas with ongoing task demands. {\textcopyright} 2013 Elsevier Ltd.},
author = {Ghosh, Vanessa E. and Gilboa, Asaf},
doi = {10.1016/j.neuropsychologia.2013.11.010},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ghosh, Gilboa - 2014 - What is a memory schema A historical perspective on current neuroscience literature.pdf:pdf},
issn = {00283932},
journal = {Neuropsychologia},
keywords = {Associative network,Confabulation,Encoding,Prior knowledge,Schemas,Ventromedial prefrontal cortex},
mendeley-groups = {Lisco/Schema},
number = {1},
pages = {104--114},
publisher = {Elsevier},
title = {{What is a memory schema? A historical perspective on current neuroscience literature}},
url = {http://dx.doi.org/10.1016/j.neuropsychologia.2013.11.010},
volume = {53},
year = {2014}
}
@article{Tse2007,
abstract = {Memory encoding occurs rapidly, but the consolidation of memory in the neocortex has long been held to be a more gradual process. We now report, however, that systems consolidation can occur extremely quickly if an associative "schema" into which new information is incorporated has previously been created. In experiments using a hippocampal-dependent paired-associate task for rats, the memory of flavor-place associations became persistent over time as a putative neocortkal schema gradually developed. New traces, trained for only one trial, then became assimilated and rapidly hippocampal-independent. Schemas also played a causal role in the creation of lasting associative memory representations during one-trial learning. The concept of neocortkal schemas may unite psychological accounts of knowledge structures with neurobiological theories of systems memory consolidation.},
author = {Tse, Dorothy and Langston, Rosamund F. and Kakeyama, Masaki and Bethus, Ingrid and Spooner, Patrick A. and Wood, Emma R. and Witter, Menno P. and Morris, Richard G.M.},
doi = {10.1126/science.1135935},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tse et al. - 2007 - Schemas and memory consolidation.pdf:pdf},
issn = {00368075},
journal = {Science},
mendeley-groups = {Lisco/Memory consolidation},
number = {5821},
pages = {76--82},
title = {{Schemas and memory consolidation}},
volume = {316},
year = {2007}
}
@article{VanKesteren2012,
abstract = {Information that is congruent with existing knowledge (a schema) is usually better remembered than less congruent information. Only recently, however, has the role of schemas in memory been studied from a systems neuroscience perspective. Moreover, incongruent (novel) information is also sometimes better remembered. Here, we review lesion and neuroimaging findings in animals and humans that relate to this apparent paradoxical relationship between schema and novelty. In addition, we sketch a framework relating key brain regions in medial temporal lobe (MTL) and medial prefrontal cortex (mPFC) during encoding, consolidation and retrieval of information as a function of its congruency with existing information represented in neocortex. An important aspect of this framework is the efficiency of learning enabled by congruency-dependent MTL-mPFC interactions. {\textcopyright} 2012 Elsevier Ltd.},
author = {{Van Kesteren}, Marlieke T.R. and Ruiter, Dirk J. and Fern{\'{a}}ndez, Guill{\'{e}}n and Henson, Richard N.},
doi = {10.1016/j.tins.2012.02.001},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Kesteren et al. - 2012 - How schema and novelty augment memory formation.pdf:pdf},
issn = {01662236},
journal = {Trends in Neurosciences},
keywords = {Medial prefrontal cortex,Medial temporal lobe,Memory formation,Novelty,Prediction error,Schema},
mendeley-groups = {Lisco},
number = {4},
pages = {211--219},
title = {{How schema and novelty augment memory formation}},
volume = {35},
year = {2012}
}

@article{Ergo2020,
abstract = {<p>Learning based on reward prediction error (RPE) was originally proposed in the context of nondeclarative memory. We postulate that RPE may support declarative memory as well. Indeed, recent years have witnessed a number of independent empirical studies reporting effects of RPE on declarative memory. We provide a brief overview of these studies, identify emerging patterns, and discuss open issues such as the role of signed versus unsigned RPEs in declarative learning.</p>},
author = {Ergo, Kate and Loof, Esther De and Verguts, Tom},
doi = {10.1016/J.TICS.2020.02.009},
issn = {1364-6613},
journal = {Trends in Cognitive Sciences},
keywords = {declarative memory,reinforcement learning,reward prediction error},
mendeley-groups = {Lisco/computational models/Reinforcement learning},
month = {may},
number = {5},
pages = {388--397},
pmid = {32298624},
publisher = {Elsevier},
title = {{Reward Prediction Error and Declarative Memory}},
url = {http://www.cell.com/article/S1364661320300668/fulltext http://www.cell.com/article/S1364661320300668/abstract https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(20)30066-8},
volume = {24},
year = {2020}
}
@article{McClelland1995a,
abstract = {Damage to the hippocampal system disrupts recent memory but leaves remote memory intact. The account presented here suggests that memories are first stored via synaptic changes in the hippo-campal system, that these changes support reinstatement of recent memories in the neocortex, that neocortical synapses change a little on each reinstatement, and that remote memory is based on accumulated neocortical changes. Models that learn via changes to connections help explain this organization. These models discover the structure in ensembles of items if learning of each item is gradual and interleaved with learning about other items. This suggests that the neocortex learns slowly to discover the structure in ensembles of experiences. The hippocampal system permits rapid learning of new items without disrupting this structure, and reinstatement of new memories in-terleaves them with others to integrate them into structured neocortical memory systems.},
author = {McClelland, James L and McNaughton, Bruce L and O'Reilly, Randall C},
doi = {10.1037/0033-295X.102.3.419},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McClelland, McNaughton, O'Reilly - 1995 - Why there are complementary learning systems in the hippocampus and neocortex Insights from th.pdf:pdf},
isbn = {0033-295X (Print)\r0033-295X (Linking)},
issn = {0033-295X},
journal = {Psychological Review},
mendeley-groups = {Lisco/computational models},
number = {3},
pages = {419--457},
pmid = {7624455},
title = {{Why there are complementary learning systems in the hippocampus and neocortex: Insights from the successes and failures of connectionist models of learning and memory}},
volume = {102},
year = {1995}
}

@article{Friston2018,
abstract = {In the 20th century we thought the brain extracted knowledge from sensations. The 21st century witnessed a ‘strange inversion', in which the brain became an organ of inference, actively constructing explanations for what's going on ‘out there', beyond its sensory epithelia. One paper played a key role in this paradigm shift.},
author = {Friston, Karl},
doi = {10.1038/s41593-018-0200-7},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Friston - 2018 - Does predictive coding have a future.pdf:pdf},
issn = {15461726},
journal = {Nature Neuroscience},
mendeley-groups = {Lisco},
month = {aug},
number = {8},
pages = {1019--1021},
publisher = {Nature Publishing Group},
title = {{Does predictive coding have a future?}},
volume = {21},
year = {2018}
}
@article{Bein2015,
abstract = {A fundamental challenge in the study of learning and memory is to understand the role of existing knowledge in the encoding and retrieval of new episodic information. The importance of prior knowledge in memory is demonstrated in the congruency effect—the robust finding wherein participants display better memory for items that are compatible, rather than incompatible, with their pre-existing semantic knowledge. Despite its robustness, the mechanism underlying this effect is not well understood. In four studies, we provide evidence that demonstrates the privileged explanatory power of the elaboration-integration account over alternative hypotheses. Furthermore, we question the implicit assumption that the congruency effect pertains to the truthfulness/sensibility of a subject-predicate proposition, and show that congruency is a function of semantic relatedness between item and context words.},
author = {Bein, Oded and Livneh, Neta and Reggev, Niv and Gilead, Michael and Goshen-Gottstein, Yonatan and Maril, Anat},
doi = {10.1371/JOURNAL.PONE.0115624},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bein et al. - 2015 - Delineating the Effect of Semantic Congruency on Episodic Memory The Role of Integration and Relatedness.pdf:pdf},
issn = {1932-6203},
journal = {PLOS ONE},
keywords = {Dogs,Information retrieval,Memory,Memory recall,Mnemonics,Semantics,Spinach,Word recognition},
mendeley-groups = {Lisco/PE and episodic memory,Episodic memory},
month = {feb},
number = {2},
pages = {e0115624},
publisher = {Public Library of Science},
title = {{Delineating the Effect of Semantic Congruency on Episodic Memory: The Role of Integration and Relatedness}},
url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115624},
volume = {10},
year = {2015}
}
@article{BrodGarvinShingYee2019,
author = {{Brod, Garvin, Shing, Yee}, Lee},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brod - Unknown - A Boon and a Bane Comparing the Effects of Prior Knowledge on Memory Across the Lifespan.pdf:pdf},
mendeley-groups = {Lisco/PE and episodic memory,Episodic memory},
title = {{A Boon and a Bane: Comparing the Effects of Prior Knowledge on Memory Across the Lifespan}},
url = {https://www.researchgate.net/publication/330440758},
year = {2019}
}
@article{Kafkas2018,
abstract = {Our ability to make predictions and monitor regularities has a profound impact on the way we perceive the environment, but the effect this mechanism has on memory is not well understood. In four experiments, we explored the effects on memory of the expectation status of information at encoding or at retrieval. In a rule-learning task participants learned a contingency relationship between 6 different symbols and the type of stimulus that followed each one. Either at encoding (Experiments 1a and 1b) or at retrieval (Experiments 2a and 2b), the established relationship was violated for a subset of stimuli resulting in the presentation of both expected and unexpected stimuli. The expectation status of the stimuli was found to have opposite effects on familiarity and recollection performance, the two kinds of memory that support recognition memory. At encoding (Experiments 1a and 1b), the presentation of expected stimuli selectively enhanced subsequent familiarity performance, while unexpected stimuli selectively enhanced subsequent recollection. Similarly, at retrieval (Experiments 2a and 2b), expected stimuli were more likely to be deemed familiar than unexpected stimuli, whereas unexpected stimuli were more likely to be recollected than were expected stimuli. These findings suggest that two separate memory enhancement mechanisms exist; one sensitive and modulating the accuracy of memory for the contextually distinctive or unexpected, and the other sensitive to and modulating the accuracy of memory for the expected. Therefore, the degree to which information fits with expectation has critical implications for the type of computational mechanism that will be engaged to support memory.},
author = {Kafkas, Alex and Montaldi, Daniela},
doi = {10.1016/J.COGNITION.2018.07.010},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kafkas, Montaldi - 2018 - Expectation affects learning and modulates memory experience at retrieval.pdf:pdf},
issn = {0010-0277},
journal = {Cognition},
keywords = {Context,Expectation,Familiarity,Pattern separation,Recollection,Similarity},
mendeley-groups = {Lisco/PE and episodic memory,Episodic memory},
month = {nov},
pages = {123--134},
publisher = {Elsevier},
title = {{Expectation affects learning and modulates memory experience at retrieval}},
volume = {180},
year = {2018}
}
@article{Daw2011,
abstract = {Researchers have recently begun to integrate computational models into the analysis of neural and behavioural data, particularly in experiments on reward learning and decision making. This chapter aims to review and rationalize these methods. It exposes these tools as instances of broadly applicable statistical techniques, considers the questions they are suited to answer, provides a practical tutorial and tips for their effective use, and, finally, suggests some directions for extension or improvement. The techniques are illustrated with fits of simple models to simulated datasets. Throughout, the chapter flags interpretational and technical pitfalls of which authors, reviewers, and readers should be aware.},
author = {Daw, Nathaniel D.},
doi = {10.1093/acprof:oso/9780199600434.003.0001},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Daw - 2011 - Trial-by-trial data analysis using computational models.pdf:pdf},
isbn = {9780191725623},
journal = {Decision Making, Affect, and Learning: Attention and Performance XXIII},
keywords = {Computational models,Data analysis,Decision making,Neural data,Reward learning,Statistical methods},
mendeley-groups = {Lisco/computational models},
pages = {1--26},
title = {{Trial-by-trial data analysis using computational models}},
year = {2011}
}
@article{McClure2003,
abstract = {Functional MRI experiments in human subjects strongly suggest that the striatum participates in processing information about the predictability of rewarding stimuli. However, stimuli can be unpredictable in character (what stimulus arrives next), unpredictable in time (when the stimulus arrives), and unpredictable in amount (how much arrives). These variables have not been dissociated in previous imaging work in humans, thus conflating possible interpretations of the kinds of expectation errors driving the measured brain responses. Using a passive conditioning task and fMRI in human subjects, we show that positive and negative prediction errors in reward delivery time correlate with BOLD changes in human striatum, with the strongest activation lateralized to the left putamen. For the negative prediction error, the brain response was elicited by expectations only and not by stimuli presented directly; that is, we measured the brain response to nothing delivered (juice expected but not delivered) contrasted with nothing delivered (nothing expected).},
author = {McClure, Samuel M. and Berns, Gregory S. and Montague, P. Read},
doi = {10.1016/S0896-6273(03)00154-5},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McClure, Berns, Montague - 2003 - Temporal Prediction Errors in a Passive Learning Task Activate Human Striatum.pdf:pdf},
issn = {0896-6273},
journal = {Neuron},
mendeley-groups = {Lisco/computational models/Reinforcement learning},
month = {apr},
number = {2},
pages = {339--346},
publisher = {Cell Press},
title = {{Temporal Prediction Errors in a Passive Learning Task Activate Human Striatum}},
volume = {38},
year = {2003}
}
@article{Schultz1997,
abstract = {The capacity to predict future events permits a creature to detect, model, and manipulate the causal structure of its interactions with its environment. Behavioral experiments suggest that learning is driven by changes in the expectations about future salient events such as rewards and punishments. Physiological work has recently complemented these studies by identifying dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events. Taken together, these findings can be understood through quantitative theories of adaptive optimizing control.},
author = {Schultz, Wolfram and Dayan, Peter and Montague, P. Read},
doi = {10.1126/SCIENCE.275.5306.1593},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/W, P, PR - 1997 - A neural substrate of prediction and reward.pdf:pdf},
issn = {0036-8075},
journal = {Science (New York, N.Y.)},
keywords = {Algorithms,Animals,Computer Simulation,Conditioning,Cues,Dopamine / physiology*,Learning*,MEDLINE,Mesencephalon / physiology*,Models,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Neurological*,Neurons / physiology*,Non-U.S. Gov't,P Dayan,P R Montague,P.H.S.,Psychological,PubMed Abstract,Rats,Research Support,Review,Reward*,U.S. Gov't,W Schultz,doi:10.1126/science.275.5306.1593,pmid:9054347},
mendeley-groups = {Lisco/computational models/Reinforcement learning},
number = {5306},
pages = {1593--1599},
pmid = {9054347},
publisher = {Science},
title = {{A neural substrate of prediction and reward}},
url = {https://pubmed.ncbi.nlm.nih.gov/9054347/},
volume = {275},
year = {1997}
}
@article{Schultz2016,
abstract = {Reward prediction errors consist of the differences between received and predicted rewards. They are crucial for basic forms of learning about rewards and make us strive for more rewards-an evolutionary beneficial trait. Most dopamine neurons in the midbrain of humans, monkeys, and rodents signal a reward prediction error; they are activated by more reward than predicted (positive prediction error), remain at baseline activity for fully predicted rewards, and show depressed activity with less reward than predicted (negative prediction error). The dopamine signal increases nonlinearly with reward value and codes formal economic utility. Drugs of addiction generate, hijack, and amplify the dopamine reward signal and induce exaggerated, uncontrolled dopamine effects on neuronal plasticity. The striatum, amygdala, and frontal cortex also show reward prediction error coding, but only in subpopulations of neurons. Thus, the important concept of reward prediction errors is implemented in neuronal hardware.},
author = {Schultz, Wolfram},
doi = {10.31887/dcns.2016.18.1/wschultz},
issn = {12948322},
journal = {Dialogues in Clinical Neuroscience},
keywords = {Dopamine,Neuron,Neurophysiology,Prediction,Reward,Striatum,Substantia nigra,Ventral tegmental area},
mendeley-groups = {Lisco/Predictive processing,Lisco/computational models,Lisco/PE and episodic memory},
month = {mar},
number = {1},
pages = {23--32},
pmid = {27069377},
publisher = {Les Laboratoires Seriver},
title = {{Dopamine reward prediction error coding}},
url = {/pmc/articles/PMC4826767/ /pmc/articles/PMC4826767/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4826767/},
volume = {18},
year = {2016}
}
@article{Steinberg2013,
abstract = {Unexpected rewards activate midbrain dopamine neurons, and this response is proposed to support learning by signaling discrepancies between actual and expected outcomes. Here the authors use optogenetic stimulation to demonstrate a causal role for temporally precise dopamine neuron signaling in cue-reward learning. Situations in which rewards are unexpectedly obtained or withheld represent opportunities for new learning. Often, this learning includes identifying cues that predict reward availability. Unexpected rewards strongly activate midbrain dopamine neurons. This phasic signal is proposed to support learning about antecedent cues by signaling discrepancies between actual and expected outcomes, termed a reward prediction error. However, it is unknown whether dopamine neuron prediction error signaling and cue-reward learning are causally linked. To test this hypothesis, we manipulated dopamine neuron activity in rats in two behavioral procedures, associative blocking and extinction, that illustrate the essential function of prediction errors in learning. We observed that optogenetic activation of dopamine neurons concurrent with reward delivery, mimicking a prediction error, was sufficient to cause long-lasting increases in cue-elicited reward-seeking behavior. Our findings establish a causal role for temporally precise dopamine neuron signaling in cue-reward learning, bridging a critical gap between experimental evidence and influential theoretical frameworks.},
author = {Steinberg, Elizabeth E and Keiflin, Ronald and Boivin, Josiah R and Witten, Ilana B and Deisseroth, Karl and Janak, Patricia H},
doi = {10.1038/nn.3413},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Steinberg et al. - 2013 - A causal link between prediction errors, dopamine neurons and learning.pdf:pdf},
issn = {1546-1726},
journal = {Nature Neuroscience 2013 16:7},
keywords = {Classical conditioning},
mendeley-groups = {Lisco/computational models/Reinforcement learning},
month = {may},
number = {7},
pages = {966--973},
publisher = {Nature Publishing Group},
title = {{A causal link between prediction errors, dopamine neurons and learning}},
url = {https://www.nature.com/articles/nn.3413},
volume = {16},
year = {2013}
}
@article{de2018signed,
  title={Signed reward prediction errors drive declarative learning},
  author={De Loof, Esther and Ergo, Kate and Naert, Lien and Janssens, Clio and Talsma, Durk and Van Opstal, Filip and Verguts, Tom},
  journal={PLoS One},
  volume={13},
  number={1},
  pages={e0189212},
  year={2018},
  publisher={Public Library of Science San Francisco, CA USA}
}
@article{raftery1995bayesian,
  title={Bayesian model selection in social research},
  author={Raftery, Adrian E},
  journal={Sociological methodology},
  pages={111--163},
  year={1995},
  publisher={JSTOR}
}
@article{gluth2017attraction,
  title={The attraction effect modulates reward prediction errors and intertemporal choices},
  author={Gluth, Sebastian and Hotaling, Jared M and Rieskamp, J{\"o}rg},
  journal={Journal of Neuroscience},
  volume={37},
  number={2},
  pages={371--382},
  year={2017},
  publisher={Soc Neuroscience}
}
@article{bates2014fitting,
  title={Fitting linear mixed-effects models using lme4},
  author={Bates, Douglas and M{\"a}chler, Martin and Bolker, Ben and Walker, Steve},
  journal={arXiv preprint arXiv:1406.5823},
  year={2014}
}
@article{barr2013random,
  title={Random effects structure for testing interactions in linear mixed-effects models},
  author={Barr, Dale J},
  journal={Frontiers in psychology},
  volume={4},
  pages={328},
  year={2013},
  publisher={Frontiers}
}
@article{VanKesteren2013,
abstract = {Newly learned information that is congruent with a preexisting schema is often better remembered than information that is incongruent. This schema effect on memory has previously been associated to more efficient encoding and consolidation mechanisms. However, this effect is not always consistently supported in the literature, with differential schema effects reported for different types of memory, different retrieval cues, and the possibility of time-dependent effects related to consolidation processes. To examine these effects more directly, we tested participants on two different types of memory (item recognition and associative memory) for newly encoded visuo-tactile associations at different study-test intervals, thus probing memory retrieval accuracy for schema-congruent and schema-incongruent items and associations at different time points (t = 0, t = 20, and t = 48 hours) after encoding. Results show that the schema effect on visual item recognition only arises after consolidation, while the schema effect on associative memory is already apparent immediately after encoding, persisting, but getting smaller over time. These findings give further insight into different factors influencing the schema effect on memory, and can inform future schema experiments by illustrating the value of considering effects of memory type and consolidation on schema-modulated retrieval. {\textcopyright} 2013 van Kesteren et al.},
author = {van Kesteren, Marlieke T.R. and Rijpkema, Mark and Ruiter, Dirk J. and Fern{\'{a}}ndez, Guill{\'{e}}n},
doi = {10.1371/journal.pone.0056155},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/van Kesteren et al. - 2013 - Consolidation Differentially Modulates Schema Effects on Memory for Items and Associations.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
mendeley-groups = {Lisco/Memory consolidation},
month = {feb},
number = {2},
publisher = {Public Library of Science},
title = {{Consolidation Differentially Modulates Schema Effects on Memory for Items and Associations}},
volume = {8},
year = {2013}
}
@article{Bethus2010,
abstract = {Three experiments investigated the role in memory processing of dopamine (DA) afferents to the hippocampus (HPC) that arise from the ventral tegmental area. One hypothesis is that D1/D5 receptor activation in HPC is necessary for the encoding of novel, episodic-like information; the other is that DA activation ensures the greater temporal persistence of transient hippocampal memory traces. Rats ( n = 35) were trained, in separate experiments using an episodic-like memory task, to learn six paired associates (PAs) in an “event arena” involving a repeated association between specific flavors of food and locations in space. After 6 weeks of training, rats had learned a “schema” such that two new paired associates could be acquired in a single trial in one session (episodic-like memory). We show that encoding of novel PAs is sensitive to intrahippocampal microinfusion of the NMDA antagonist d-AP-5. Experiment 1 established that intrahippocampal infusion of the D1/D5 dopaminergic antagonist SCH23390 [ R (+)-7-chloro-8-hydroxy-3-methyl-1-phenyl-2,3,4,5-tetrahydro-1 H -3-benzazepine hydrochloride] before encoding of new PAs caused impaired memory 24 h later but that SCH23390 had no effect on the later memory of previously established PAs. Experiment 2 established that SCH23390 modulated the persistence of new memories over time (30 min vs 24 h) rather than affecting initial encoding. Experiment 3 revealed that the impact of SCH23390 was not mediated by state dependence nor had an effect on memory retrieval. These findings support the second hypothesis and establish that persistent, long-term memory of rapid, hippocampal-mediated acquisition of new paired associates requires activation of D1/D5 receptors in HPC at or around the time of encoding.},
author = {Bethus, Ingrid and Tse, Dorothy and Morris, Richard G. M.},
doi = {10.1523/JNEUROSCI.2721-09.2010},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bethus, Tse, Morris - 2010 - Dopamine and Memory Modulation of the Persistence of Memory for Novel Hippocampal NMDA Receptor-Dependent P.pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
mendeley-groups = {Lisco/hippocampus},
month = {feb},
number = {5},
pages = {1610--1618},
pmid = {20130171},
publisher = {Society for Neuroscience},
title = {{Dopamine and Memory: Modulation of the Persistence of Memory for Novel Hippocampal NMDA Receptor-Dependent Paired Associates}},
url = {https://www.jneurosci.org/content/30/5/1610 https://www.jneurosci.org/content/30/5/1610.abstract},
volume = {30},
year = {2010}
}

@article{ESBromberg-Martin2011,
abstract = {Humans and animals have the ability to predict future events, which they cultivate by continuously searching their environment for sources of predictive information. However, little is known about the neural systems that motivate this behavior. We hypothesized that information-seeking is assigned value by the same circuits that support reward-seeking, such that neural signals encoding reward prediction errors (RPEs) include analogous information prediction errors (IPEs). To test this, we recorded from neurons in the lateral habenula, a nucleus that encodes RPEs, while monkeys chose between cues that provided different chances to view information about upcoming rewards. We found that a subpopulation of lateral habenula neurons transmitted signals resembling IPEs, responding when reward information was unexpectedly cued, delivered or denied. These signals evaluated information sources reliably, even when the monkey's decisions did not. These neurons could provide a common instructive signal for reward-seeking and information-seeking behavior. {\textcopyright} 2011 Nature America, Inc. All rights reserved.},
author = {{ES Bromberg-Martin}, O Hikosaka},
doi = {10.1038/nn.2902},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/ES Bromberg-Martin - 2011 - Lateral habenula neurons signal errors in the prediction of reward information.pdf:pdf},
journal = {Nat. Neurosci.},
mendeley-groups = {Lisco/computational models/Reinforcement learning},
month = {sep},
number = {9},
pages = {1209--1216},
title = {{Lateral habenula neurons signal errors in the prediction of reward information}},
volume = {14},
year = {2011}
}
@article{Niv2011,
abstract = {Knowledge is not just power. Even if advance information can not influence an upcoming event, people (and animals) prefer to know ahead of time what the outcome will be. According to the firing patterns of neurons in the lateral habenula, from the brain's perspective, knowledge is also water—or at least its equivalent in terms of reward.},
author = {Niv, Yael and Chan, Stephanie},
doi = {10.1038/nn.2918},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Niv, Chan - 2011 - On the value of information and other rewards.pdf:pdf},
issn = {1546-1726},
journal = {Nature Neuroscience 2011 14:9},
keywords = {Cognitive neuroscience,Neuronal development,Reward},
mendeley-groups = {Lisco/computational models/Reinforcement learning},
month = {aug},
number = {9},
pages = {1095--1097},
publisher = {Nature Publishing Group},
title = {{On the value of information and other rewards}},
url = {https://www.nature.com/articles/nn.2918},
volume = {14},
year = {2011}
}
@article{Yu2005,
abstract = {Uncertainty in various forms plagues our interactions with the environment. In a Bayesian statistical framework, optimal inference and prediction, based on unreliable observations in changing contexts, require the representation and manipulation of different forms of uncertainty. We propose that the neuromodulators acetylcholine and norepinephrine play a major role in the brain's implementation of these uncertainty computations. Acetylcholine signals expected uncertainty, coming from known unreliability of predictive cues within a context. Norepinephrine signals unexpected uncertainty, as when unsignaled context switches produce strongly unexpected observations. These uncertainty signals interact to enable optimal inference and learning in noisy and changeable environments. This formulation is consistent with a wealth of physiological, pharmacological, and behavioral data implicating acetylcholine and norepinephrine in specific aspects of a range of cognitive processes. Moreover, the model suggests a class of attentional cueing tasks that involve both neuromodulators and shows how their interactions may be part-antagonistic, part-synergistic. Copyright {\textcopyright}2005 by Elsevier Inc.},
author = {Yu, Angela J. and Dayan, Peter},
doi = {10.1016/J.NEURON.2005.04.026},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Dayan - 2005 - Uncertainty, Neuromodulation, and Attention.pdf:pdf},
issn = {0896-6273},
journal = {Neuron},
mendeley-groups = {Lisco/computational models/Reinforcement learning},
month = {may},
number = {4},
pages = {681--692},
publisher = {Cell Press},
title = {{Uncertainty, Neuromodulation, and Attention}},
volume = {46},
year = {2005}
}
@article{wittmann2008mesolimbic,
  title={Mesolimbic interaction of emotional valence and reward improves memory formation},
  author={Wittmann, Bianca C and Schiltz, Kolja and Boehler, C Nico and D{\"u}zel, Emrah},
  journal={Neuropsychologia},
  volume={46},
  number={4},
  pages={1000--1008},
  year={2008},
  publisher={Elsevier}
}
@article{mather2011positive,
  title={Positive outcomes enhance incidental learning for both younger and older adults},
  author={Mather, Mara and Schoeke, Andrej},
  journal={Frontiers in neuroscience},
  volume={5},
  pages={129},
  year={2011},
  publisher={Frontiers}
}
@article{holtje2018electrophysiological,
  title={Electrophysiological reward signals predict episodic memory for immediate and delayed positive feedback events},
  author={H{\"o}ltje, Gerrit and Mecklinger, Axel},
  journal={Brain research},
  volume={1701},
  pages={64--74},
  year={2018},
  publisher={Elsevier}
}
@article{wittmann2005reward,
  title={Reward-related FMRI activation of dopaminergic midbrain is associated with enhanced hippocampus-dependent long-term memory formation},
  author={Wittmann, Bianca C and Schott, Bj{\"o}rn H and Guderian, Sebastian and Frey, Julietta U and Heinze, Hans-Jochen and D{\"u}zel, Emrah},
  journal={Neuron},
  volume={45},
  number={3},
  pages={459--467},
  year={2005},
  publisher={Elsevier}
}
@article{Lefebvre2017,
abstract = {When forming and updating beliefs about future life outcomes, people tend to consider good news and to disregard bad news. This tendency is assumed to support the optimism bias. Whether this learning bias is specific to 'high-level' abstract belief update or a particular expression of a more general 'low-level' reinforcement learning process is unknown. Here we report evidence in favour of the second hypothesis. In a simple instrumental learning task, participants incorporated better-than-expected outcomes at a higher rate than worse-than-expected ones. In addition, functional imaging indicated that inter-individual difference in the expression of optimistic update corresponds to enhanced prediction error signalling in the reward circuitry. Our results constitute a step towards the understanding of the genesis of optimism bias at the neurocomputational level. F rancis Bacon wrote 1 : "It is the peculiar and perpetual error of the human understanding to be more moved and excited by affirmatives than negatives; whereas it ought properly to hold itself indifferently disposed towards both alike. " People typically overestimate the likelihood of positive events and underestimate the likelihood of negative events. This cognitive trait in (healthy) humans is known as the optimism bias and has been repeatedly evidenced in many different guises and populations 2-4 such as students projecting their salary after graduation 5 , women estimating their risk of getting breast cancer 6 or heavy smokers assessing their risk of premature mortality 7. One mechanism hypothesized to underlie this phenomenon is an asymmetry in belief updating, colloquially referred to as the 'good news/bad news effect' 8,9. Preferentially revising one's beliefs when provided with favourable compared with unfavourable information constitutes a learning bias that could, in principle, generate and sustain an overestimation of the likelihood of desired events and a con-comitant underestimation of the likelihood of undesired events (optimism bias) 10. This good news/bad news effect has recently been demonstrated in the case where outcomes are hypothetical future prospects associated with a strong a priori desirability or undesirability (estimation of post-graduation salary or the probability of getting cancer) 5,6. In this experimental context, belief formation triggers complex interactions between episodic, affective and executive cognitive functions 8,9,11 , and belief updating relies on a learning process involving abstract probabilistic information 8,12-14. However, it remains unclear whether this learning asymmetry also applies to immediate reinforcement events driving instrumental learning directed to affectively neutral options (with no a priori desirability or undesir-ability). If an asymmetric update were also found in a task involving neutral items and direct feedback, then the good news/bad news effect could be considered as a specific-cognitive-manifestation of a general reinforcement learning asymmetry. If the asymmetry were not found at the basic reinforcement learning level, this would mean that the asymmetry is specific to abstract belief updating, and this would require a theory explaining this discrepancy. To arbitrate between these two alternative hypotheses, we fitted the instrumental behaviour of subjects performing a simple two-armed bandit task, involving neutral stimuli and actual and immediate monetary outcomes, with two learning models. The first model (a standard reinforcement learning (RL) algorithm) confounded individual learning rates for positive and negative feedback, and the second one differentiated them, potentially accounting for learning asymmetries. Over two experiments, we found that subjects' behaviour was better explained by the asym-metric model, with an overall difference in learning rates consistent with preferential learning from positive, compared with negative, prediction errors. Previous studies also suggest that the good news/bad news effect is highly variable across subjects 12. Behavioural differences in optimistic beliefs and optimistic update have been shown to be reflected by differences in brain activation in the prefrontal cortex 8. However, the question remains whether and how such inter-individual behavioural differences are related to the inter-individual neural differences in the extensively documented reward circuitry 15. Our imaging results indicate that inter-individual variability in the tendency to optimistic learning correlates with prediction-error-related signals in the reward system, including the striatum and the ventro-medial prefrontal cortex (vmPFC). results Behavioural task and dependent variables. Healthy subjects performed a probabilistic instrumental learning task with monetary feedback, previously used in brain imaging, pharmacological and clinical studies 16-18 (Fig. 1a). In this task, options (abstract cues) were presented in fixed pairs (conditions). In all conditions, each cue was associated with a stationary probability of reward.},
author = {Lefebvre, Germain and Lebreton, Ma{\"{e}}l and Meyniel, Florent and Bourgeois-Gironde, Sacha and Palminteri, Stefano},
doi = {10.1038/s41562-017-0067},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lefebvre et al. - 2017 - Behavioural and neural characterization of optimistic reinforcement learning.pdf:pdf},
mendeley-groups = {Lisco/computational models/Reinforcement learning,Lisco/Self-Bias},
title = {{Behavioural and neural characterization of optimistic reinforcement learning}},
url = {www.nature.com/nathumbehav},
year = {2017}
}
@article{sharot2016forming,
  title={Forming beliefs: Why valence matters},
  author={Sharot, Tali and Garrett, Neil},
  journal={Trends in cognitive sciences},
  volume={20},
  number={1},
  pages={25--33},
  year={2016},
  publisher={Elsevier}
}
@article{sharot2007neural,
  title={Neural mechanisms mediating optimism bias},
  author={Sharot, Tali and Riccardi, Alison M and Raio, Candace M and Phelps, Elizabeth A},
  journal={Nature},
  volume={450},
  number={7166},
  pages={102--105},
  year={2007},
  publisher={Nature Publishing Group}
}
@article{Shohamy2010,
abstract = {Memory is essential to adaptive behavior because it allows past experience to guide choices. Emerging findings indicate that the neurotransmitter dopamine, which signals motivationally important events, also modulates the hippocampus, a crucial brain system for long-term memory. Here we review recent evidence that highlights multiple mechanisms whereby dopamine biases memory towards events that are of motivational significance. These effects take place over a variety of timescales, permitting both expectations and outcomes to influence memory. Thus, dopamine ensures that memories are relevant and accessible for future adaptive behavior, a concept we refer to as 'adaptive memory'. Understanding adaptive memory at biological and psychological levels helps to resolve a fundamental challenge in memory research: explaining what is remembered, and why. {\textcopyright} 2010 Elsevier Ltd.},
author = {Shohamy, Daphna and Adcock, R. Alison},
doi = {10.1016/J.TICS.2010.08.002},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shohamy, Adcock - 2010 - Dopamine and adaptive memory.pdf:pdf},
issn = {1364-6613},
journal = {Trends in Cognitive Sciences},
mendeley-groups = {Lisco/EM and feedback},
month = {oct},
number = {10},
pages = {464--472},
pmid = {20829095},
publisher = {Elsevier Current Trends},
title = {{Dopamine and adaptive memory}},
volume = {14},
year = {2010}
}
@article{sharot2011unrealistic,
  title={How unrealistic optimism is maintained in the face of reality},
  author={Sharot, Tali and Korn, Christoph W and Dolan, Raymond J},
  journal={Nature neuroscience},
  volume={14},
  number={11},
  pages={1475--1479},
  year={2011},
  publisher={Nature Publishing Group}
}

@misc{ortiz2021not,
  title={Not what U expect: Effects of Prediction Errors on Episodic Memory.},
   howpublished = "\url{https://psyarxiv.com/8dwb3/}",

  author={Ortiz-Tudela, Javier and Nolden, Sophie and Pupillo, Francesco and Ehrlich, Isabelle and Schommartz, Iryna and Turan, G{\"o}zem and Shing, Yee Lee},
  year={2021},
  publisher={PsyArXiv}

}
@article{lemon2006dopamine,
  title={Dopamine D1/D5 receptors gate the acquisition of novel information through hippocampal long-term potentiation and long-term depression},
  author={Lemon, Neal and Manahan-Vaughan, Denise},
  journal={Journal of Neuroscience},
  volume={26},
  number={29},
  pages={7723--7729},
  year={2006},
  publisher={Soc Neuroscience}
}
@article{rosen2015midbrain,
  title={Midbrain dopamine neurons bidirectionally regulate CA3-CA1 synaptic drive},
  author={Rosen, Zev B and Cheung, Stephanie and Siegelbaum, Steven A},
  journal={Nature neuroscience},
  volume={18},
  number={12},
  pages={1763--1771},
  year={2015},
  publisher={Nature Publishing Group}
}
@article{Davidow2016,
abstract = {Adolescents are notorious for engaging in reward-seeking behaviors, a tendency attributed to heightened activity in the brain's reward systems during adolescence. It has been suggested that reward sensitivity in adolescence might be adaptive, but evidence of an adaptive role has been scarce. Using a probabilistic reinforcement learning task combined with reinforcement learning models and fMRI, we found that adolescents showed better reinforcement learning and a stronger link between reinforcement learning and episodic memory for rewarding outcomes. This behavioral benefit was related to heightened prediction error-related BOLD activity in the hippocampus and to stronger functional connectivity between the hippocampus and the striatum at the time of reinforcement. These findings reveal an important role for the hippocampus in reinforcement learning in adolescence and suggest that reward sensitivity in adolescence is related to adaptive differences in how adolescents learn from experience.},
author = {Davidow, Juliet Y. and Foerde, Karin and Galv{\'{a}}n, Adriana and Shohamy, Daphna},
doi = {10.1016/j.neuron.2016.08.031},
file = {:home/francesco/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Davidow et al. - 2016 - An Upside to Reward Sensitivity The Hippocampus Supports Enhanced Reinforcement Learning in Adolescence.pdf:pdf},
issn = {10974199},
journal = {Neuron},
mendeley-groups = {Lisco/Methods},
number = {1},
pages = {93--99},
pmid = {27710793},
title = {{An Upside to Reward Sensitivity: The Hippocampus Supports Enhanced Reinforcement Learning in Adolescence}},
volume = {92},
year = {2016}
}
@article{mather2011arousal,
  title={Arousal-biased competition in perception and memory},
  author={Mather, Mara and Sutherland, Matthew R},
  journal={Perspectives on psychological science},
  volume={6},
  number={2},
  pages={114--133},
  year={2011},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}
@article{watanabe2019reward,
  title={Reward-driven arousal impacts preparation to perform a task via amygdala--caudate mechanisms},
  author={Watanabe, Noriya and Bhanji, Jamil P and Ohira, Hideki and Delgado, Mauricio R},
  journal={Cerebral Cortex},
  volume={29},
  number={7},
  pages={3010--3022},
  year={2019},
  publisher={Oxford University Press}
}
@article{Behrens2007,
abstract = {Our decisions are guided by outcomes that are associated with decisions made in the past. However, the amount of influence each past outcome has on our next decision remains unclear. To ensure optimal decision-making, the weight given to decision outcomes should reflect their salience in predicting future outcomes, and this salience should be modulated by the volatility of the reward environment. We show that human subjects assess volatility in an optimal manner and adjust decision-making accordingly. This optimal estimate of volatility is reflected in the fMRI signal in the anterior cingulate cortex (ACC) when each trial outcome is observed. When a new piece of information is witnessed, activity levels reflect its salience for predicting future outcomes. Furthermore, variations in this ACC signal across the population predict variations in subject learning rates. Our results provide a formal account of how we weigh our different experiences in guiding our future actions. The statistics of the environment have been shown to exert optimal influence on the organization and function of perceptual and motor systems 1,2. However, higher-level processes, such as voluntary choice, have often proved to be immune to such statistical description. Instead, recent descriptions of choice have emphasized its unpredictable nature 3. We report interlinked findings that challenge this perspective and suggest that an estimate of a higher-order statistical feature of the environment affects the way that voluntary decisions are made. The decisions that we make are guided by the outcomes of similar decisions made in the past 4-7. Understanding how we build such associations between events, and therefore between actions and their outcomes, has been the principal goal of learning theory. According to models of reinforcement learning 8,9 , when an animal receives new information, it updates its belief about the environment in proportion to its prediction error, d, which is the difference between the expected and actual outcomes 8,9. It is often overlooked, however, that d must be multiplied by an additional factor called the learning rate, a (refs. 8,9), to determine the degree by which the action value is updated 10. Although the learning rate is a fundamental feature of the behavior of all organisms and even artificial agents, reflecting the rate at which new information replaces old, it has never been clear whether, how or why it changes 11. In neuroscience, it is customary to fit the learning rate to observed data 5. In psychology, attempts have been made to determine its influencing factors 8,12,13 , but the accounts have been contested. Bayesian accounts of learning propose formal strategies for optimally updating beliefs when new data are observed 14. Applied to reinforcement learning, they suggest that a should depend on the current levels of uncertainty in the estimate of the action's value. This uncertainty is determined by the statistics of the reward environment (for example 10,11,15-17). In circumstances where recent experience is more predictive of the future than is distant experience, a should be large (for example, in a fast-changing, or volatile, environment), but in situations where historical information is salient, an animal should consider experiences from an extended period, using a small value for a. Short and long decision histories are corollaries of high and low learning rates, respectively. The learning rate should be set such that the organism maximizes its power to predict future outcomes, which is the goal of the learning process. Evidence that this may be the case comes from comparing studies of decision-making in macaque monkeys in which learning rates were markedly different despite many similarities in task 18,19. Furthermore, rats' ability to detect changes in reward rates depends on their previous experience of change 20. However, direct evidence that manipulations of volatility alter learning rates has been lacking, and moreover, the brain mechanisms underlying such behavior remain unclear. Here we present two experiments that investigate whether humans can track the statistics of a reward environment, and adapt their learning rate accordingly. First, we show that, in the course of a single behavioral experiment, humans can modulate their learning rate in a fashion that is predicted quantitatively by a Bayesian learner carrying out the same task. Next, using fMRI, we show that the parameter necessary for producing such behavior correlates with the blood oxygen level-dependent (BOLD) response of the ACC at the time in the trial when the key computation is being performed. RESULTS Statistics of the reward environment predict human learning Subjects carried out a decision-making task, repeatedly choosing between blue and green rectangles (Fig. 1a). This task is analogous to a weighted coin-flipping task in that either blue or green must be correct at each trial, but not both. Subjects were instructed that the chance of the correct color being blue or green depended only on the recent outcome history. However, as a result of the difference in reward magnitudes associated with blue and green options,},
author = {Behrens, Timothy E J and Woolrich, Mark W and Walton, Mark E and Rushworth, Matthew F S},
doi = {10.1038/nn1954},
file = {:Users/francesco/Library/Application Support/Mendeley Desktop/Downloaded/Behrens et al. - 2007 - Learning the value of information in an uncertain world(2).pdf:pdf},
journal = {NATURE NEUROSCIENCE},
mendeley-groups = {Lisco/PREMCE},
number = {9},
title = {{Learning the value of information in an uncertain world}},
url = {http://www.nature.com/natureneuroscience},
volume = {10},
year = {2007}
}
