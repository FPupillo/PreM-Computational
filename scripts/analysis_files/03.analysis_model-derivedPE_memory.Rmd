---
title: "Analysis - model-derived PE"
author: "Francesco Pupillo"
date: "18/06/2021"
output: 
  md_document:
    variant: markdown_github
    toc: true
    toc_depth: 6
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# model based stats
rm(list=ls())

library(ggplot2)
library(lme4)
library(dplyr)
library(reshape2)
library(lmerTest)
library(car)
library(data.table)
library(ggpubr)


# set current directory to the parent folder
setwd(dirname(getwd()))

cd<-getwd()
source("helper_functions/getPE.R")

setwd("output_files")

getwd()

```



### start with getting the exp1 data
```{r}
# get the parent folder
abs<-paste0(dirname(getwd()))

exp1<-read.csv(paste(abs, "/output_files/fittedData.exp1.Phase2.fLR_Instr.csv", sep=""))

# exclude fillers
exp1<-exp1[exp1$pred_Cond!=4,]

# select only immediate
exp1<-exp1[exp1$rec_session=="ImmediateRec",]

# exclude participants with low performance in phase1
exclPhase1<-c(7 ,16, 19, 20, 23)

exp1<-exp1[!exp1$SubNum %in% exclPhase1, ]

```


### Now exp2
```{r}
exp2<-read.csv(paste(abs, "/output_files/fittedData.exp2.Phase2.fLR_Instr.csv", sep=""))

# select only immediate
exp2<-exp2[exp2$participant<41 ,]

# select only where practice == 0
exp2<-exp2[exp2$practice==0,]

# delete the fillers
exp2<-exp2[exp2$fillers==0,]

# exclude participants with low performance in phase1
exclPhase1exp2<-c(3 ,13, 28, 36, 39)

exp2<-exp2[!exp2$SubNum %in% exclPhase1exp2, ]
```

### create PE
```{r}
# select datasets 
exp1<-getPE(exp1,3)

exp2<-getPE(exp2, 2)

# select the variables of interest
VoI<-c("pe_level", "trialN", "rec_acc", "acc", "rec_session", "SubNum", "PE",
       "rec_Obj", "scene_cat") 

exp1<-exp1[, VoI]
names(exp1)[c(1,3,4,5, 8, 9)]<-c("PE_level",  "id_acc","trial_acc", "session",
                                 "obj_file", "scn_cat")

# convert PE level as factor
exp1$PE_level<-as.factor(exp1$PE_level)

# rename PE levels
levels(exp1$PE_level) <- c("0.9", "0.1", "0.5")

# order the PE
exp1$PE_level<-factor(exp1$PE_level, level = c("0.1", "0.5",  "0.9"))

# create scene condition
exp1$scn_condition<-ifelse(exp1$PE_level=="0.5", "Flat", "Strong")

# rename scene condition
exp2$scn_condition<-as.factor(exp2$scn_condition)

levels(exp2$scn_condition)<-c("Flat", "Weak", "Strong")

#levels(exp1$trial_acc)<-c("Incorrect", "Correct")

## PE by accuracy - exp2
exp2$trial_acc<-as.factor(exp2$trial_acc)

#levels(exp2$trial_acc)<-c("Incorrect", "Correct")   

```


# Merge Them
```{r}
exp1$exp<-"Experiment1"
exp2$exp<-"Experiment2"

exp2$session<-as.character(exp2$session)
exp1$session<-as.character(exp1$session)

exp1$PE_level<-as.character(exp1$PE_level)
exp2$PE_level<-as.character(exp2$PE_level)

exp1$scn_condition<-as.character(exp1$scn_condition)
exp2$scn_condition<-as.character(exp2$scn_condition)

# retrieve the learning rates
# experiment 1
# learning rate
exp1lr<-fread(paste0(dirname(abs), "/exp1/outputs/group_level/computational_model/", 
                     "ParameterEstimation.exp1.betalimit=10.initialQ=0.33.fLR_Instr.csv"))

# select the first three rows
exp1lr<-exp1lr[,1:3]

# change the name of the variable indicating the participant
names(exp1lr)[1]<-"SubNum"

exp1<-merge(exp1, exp1lr, by = "SubNum")

# exp 2
exp2lr<-fread(paste0(dirname(abs),"/exp2/outputs/group_level/computational_model/", 
                     "ParameterEstimation.exp2.betalimit=10.initialQ=0.5.fLR_Instr.csv"))

# select the first three rows
exp2lr<-exp2lr[,1:3]

# change the name of the variable indicating the participant
names(exp2lr)[1]<-"SubNum"

exp2<-merge(exp2, exp2lr, by = "SubNum")

# add "2" in front of the subnum
exp2$SubNum<-exp2$SubNum+200
exp2<-exp2[, names(exp1)]

# merge thetwo
allData<-data.frame(rbind(exp1,exp2 ))

# rename prediction accuracy
allData$trial_acc<-ifelse(allData$trial_acc==0, "Incorrect", "Correct")

# make the "incorrect" level the baseline
allData$trial_acc<-as.factor(allData$trial_acc)
allData$trial_acc<-relevel(allData$trial_acc, ref = "Incorrect")

```



Save it
```{r}
setwd(dirname(getwd()))
getwd()
write.csv(allData, paste0(abs,"/output_files/fittedData_exp1-exp2_fLR_Instr.csv"))

```

### Visualize merged data
```{r}

# plot merged data
# with the histogram
PEDistrExpN<-ggplot(allData, aes(x= PE, fill = ""))

PEDistrExpN+
  geom_histogram(aes(y = ..density..),
                 colour = 1, fill = "white") +
  
  geom_density(alpha=.4,show.legend = FALSE)+
  theme_classic()+
  theme(
    plot.title = element_text(size = 22),
    axis.title.x = element_text(size = 20),
    axis.title.y = element_text(size = 20),
    axis.text=element_text(size=13)
  )+
  scale_fill_viridis_d()

ggsave(paste0(abs, "/figures/PE_instr_distrNOscene.exp1.exp2.png"), 
       width = 5, height = 5)


# Now PE and recognition accuracy
# plot it first
print(
  ggplot(allData, aes( x=PE, y=id_acc))+
    geom_line(stat="smooth",method = "glm", formula=y~x,method.args=list(family="binomial"), alpha=0.5)+
    aes(colour = factor(SubNum), alpha=0.3)+
    geom_smooth(method="glm",formula=y~x,method.args=list(family="binomial"), colour="black", se=T)+
    theme(strip.text.x = element_text(size = 13))+ ylim(c(0,1))+
    facet_grid(.~trial_acc)+
    theme_classic()+
    theme(
      plot.title = element_text(size = 22),
      axis.title.x = element_text(size = 20),
      axis.title.y = element_text(size = 20),
      axis.text=element_text(size=13),
    )+
    theme(strip.text.x = element_text(size = 22))+
    theme(panel.spacing = unit(1, "lines"))+
    
    #ggtitle("Experiment 2")+
    theme(legend.position = "none")+
    ylab("p(Hit)")
)

# save it
ggsave(paste0(abs, "/figures/PE_mem_fLR_instr.exp1.exp2.png"), 
       width = 7, height = 7)

```

### Analyze now
```{r}
# we need to center PE
allData$PE.c <- scale(allData$PE, center=TRUE, scale=FALSE)

# center learning rate
allData$alpha.c <- scale(allData$alpha, center=TRUE, scale=FALSE)

# center experiment 
allData$exp.c <- ifelse(allData$exp == "Experiment1", -0.5, 0.5)

# center prediction outcome
allData$trial_acc.c <- ifelse(allData$trial_acc == "Incorrect", -0.5, 0.5)

# generalized linear mixed-effects
PEbyAccAll.c<-glmer(id_acc~PEchoice.c*alpha.c*exp.c+(trial_acc.c*PEchoice.c|SubNum), family= binomial, 
                   data = allData,
                   control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))

summary(PEbyAccAll.c)

# exponentiate the beta for OR
betas<-as.data.frame(summary(PEbyAccAll.c)$coefficients)

OR<-cbind(row.names(betas),exp(betas$Estimate))

Anova(PEbyAccAll.c, type = "III")

# get bootstrapped confidenceßß intervals
#CI<-confint(PEbyAccAll.c, method=c("boot"), boot.type=c("norm"))
# save the bootstrapped confidence intervals, as it it a very time consuming computation
#save(CI, file = "CI.Rdata")
# load the data
load("S.CI.Rdata")

# exponentiate them
exp(CI)

CI

#intervals(PEbyAccAll.c)

# in the positive side
PEbyAccAllPos<-glmer(id_acc~PE+(PE|SubNum), family= binomial, 
                     data = allData[allData$trial_acc=="Correct",],
                     control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))

summary(PEbyAccAllPos)

# in the negative side
PEbyAccAllNeg<-glmer(id_acc~PE+(PE|SubNum), family= binomial, 
                     data = allData[allData$trial_acc=="Incorrect",],
                     control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))

summary(PEbyAccAllNeg)

# is there an effect of condition?
PEbyAccAllCond<-glmer(id_acc~PE*trial_acc*scn_condition+(trial_acc*PE|SubNum), family= binomial, 
                      data = allData,
                      control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=100000)))

summary(PEbyAccAllCond)


print(
  ggplot(allData, aes( x=PE, y=id_acc))+
    geom_line(stat="smooth",method = "glm", formula=y~x,method.args=list(family="binomial"), alpha=0.5)+
    aes(colour = factor(SubNum), alpha=0.3)+
    geom_smooth(method="glm",formula=y~x,method.args=list(family="binomial"), colour="black", se=T)+
    theme(strip.text.x = element_text(size = 13))+ ylim(c(0,1))+
    facet_grid(scn_condition~trial_acc+exp)+
    theme_classic()+
    theme(
      plot.title = element_text(size = 22),
      axis.title.x = element_text(size = 20),
      axis.title.y = element_text(size = 20),
      axis.text=element_text(size=20)
    )+
    theme(legend.position = "none")+
    ylab("p(Hit)")
)

```



### Analyse with quantiles
```{R}
# create a vector
binnedData<-vector()
for (s in unique(allData$SubNum)){
  
  tryCatch({
    
    # subset participant
    currdf<-allData[allData$SubNum==s,]
    
    for (trial_acc in c("Correct","Incorrect")){
      
      currfacc<-currdf[currdf$trial_acc==trial_acc,]
      
      # get quantiles
      quantiles<-quantile(currfacc$PE)
      
      # assign quantiles
      currfacc$quantile<-NA
      for (n in 1:nrow(currfacc)){
        if (currfacc$PE[n]>=quantiles[1] & currfacc$PE[n]<quantiles[2]){
          currfacc$quantile[n]<-1  
        } else if(currfacc$PE[n]>=quantiles[2] & currfacc$PE[n]<quantiles[3]){
          currfacc$quantile[n]<-2
          
        } else if (currfacc$PE[n]>=quantiles[3] & currfacc$PE[n]<quantiles[4]){
          currfacc$quantile[n]<-3
        } else if (currfacc$PE[n]>=quantiles[4] ){
          currfacc$quantile[n]<-4
        } 
      }
      
      # create mean of id_acc and P by quantile
      df<-currfacc %>%
        group_by(quantile) %>%
        dplyr::summarise(PE = mean(PE), id_acc = mean(id_acc),
                         #PE_level = unique(PE_level), 
                         SubNum = unique(SubNum), 
                         trial_acc = unique(trial_acc),
                         exp = unique(exp))
      
      
      binnedData<-rbind(binnedData, as.data.frame(df))   
    }
  },  error=function(e){cat("ERROR :",conditionMessage(e), "\n")})  
}

# visualize
binnedData$quantile<-as.factor(binnedData$quantile)

binnedData$bin<-(binnedData$quantile)

# plot
PlotBind<-ggplot(binnedData, aes(x= PE, fill=bin))
print(
  PlotBind+geom_density()+ facet_grid( trial_acc~ exp)+theme_classic()
  
)+
  theme(
    plot.title = element_text(size = 22),
    axis.title.x = element_text(size = 20),
    axis.title.y = element_text(size = 20),
    axis.text=element_text(size=13)
  )+
  scale_fill_viridis_d()+
  theme(panel.spacing = unit(1, "lines"))

ggsave(paste0(abs, "/figures/PEdistr_binned.png"), 
       width = 7, height = 7)

# take the se within-participant
data_agg<-binnedData %>%
  group_by(bin,  trial_acc, SubNum) %>%
  dplyr::summarise(id_acc = mean(id_acc, na.rm = T))

library(Rmisc)
dat_summary <- summarySEwithin(data_agg,
                               measurevar = "id_acc",
                               withinvars = c("bin", "trial_acc"), 
                               idvar = "SubNum")

data_agg$bin<-as.factor(data_agg$bin)
gplotquant<-ggplot(data_agg, aes( x=bin, y=id_acc))+
  geom_bar(aes(bin, id_acc, fill = bin),
           position="dodge",stat="summary", fun.y="mean", SE=F)+
  
  geom_errorbar(aes(y = id_acc, ymin = id_acc - se, ymax = id_acc + se),
                color = "black", width = 0.10, data=dat_summary)+
  geom_jitter(width = 0.20, alpha = 0.2)+
  
  facet_wrap(trial_acc~.)+
  theme_classic()+
  ylab("% Hit")+
  theme(legend.position = "none")+
  theme(
    plot.title = element_text(size = 30),
    axis.title.x = element_text(size = 28),
    axis.title.y = element_text(size = 28),
    axis.text=element_text(size=28)
  )+
  theme(strip.text.x = element_text(size = 28))+
  scale_fill_viridis_d(option = "cividis")


print(gplotquant)

ggsave(paste0(abs, "/figures/binnedPE_mem.png"), 
       width = 10, height = 10)

PEquant<-lmer(id_acc~bin*trial_acc*exp+(bin+trial_acc|SubNum), 
              data = binnedData)

summary(PEquant)   

Anova(PEquant, type="III")

# dropping the setup
PEquantInt<-lmer(id_acc~quantile*trial_acc+(quantile+trial_acc|SubNum), 
                 data = binnedData)

summary(PEquantInt)

library(lsmeans)

lsmeans(PEquantInt, pairwise~quantile*trial_acc)

# 0 and 1 separately
PEquantNeg<-lmer(id_acc~quantile+(1|SubNum), 
                 data = binnedData[binnedData$trial_acc=="Incorrect",])

summary(PEquantNeg)
Anova(PEquantNeg)

#lsmeans(PEquantNeg, pairwise~quantile)

PEquantPos<-lmer(id_acc~quantile+(1|SubNum), 
                 data = binnedData[binnedData$trial_acc=="Correct",])

summary(PEquantPos)     

```


# Analysis of recognition as a function of number of subsequent scenes
```{r}
# load the function
source(paste0(abs,"/helper_functions/get_number_subs_scenes.R"))

# create the variables indicating the number of subsequent scene for each image
allData<-get_number_subs_scenes(allData)

# create the model
ggplot(allData, aes( x=num_subs_scene, y=id_acc))+
  geom_line(stat="smooth",method = "glm", formula=y~x,method.args=list(family="binomial"), alpha=0.5)+
  aes(colour = factor(SubNum), alpha=0.3)+
  geom_smooth(method="glm",formula=y~x,method.args=list(family="binomial"), colour="black", se=T)+
  theme(strip.text.x = element_text(size = 13))+ ylim(c(0,1))+
  facet_grid(.~trial_acc)+
  theme_classic()+
  theme(
    plot.title = element_text(size = 22),
    axis.title.x = element_text(size = 20),
    axis.title.y = element_text(size = 20),
    axis.text=element_text(size=20)
  )+
  theme(legend.position = "none")+
  xlab("Number of Subsequent Similar Scenes")+
  ylab("p(Hit)")

ggsave(paste0(abs, "/figures/number_subs_scenes_mem.png"), 
       width = 7, height = 7)

# Analyze
model_scenenum<-glmer(id_acc~num_subs_scene*trial_acc +(num_subs_scene*trial_acc|SubNum), 
                      family = binomial, data = allData)

summary(model_scenenum)

Anova(model_scenenum, type = "II")

```

